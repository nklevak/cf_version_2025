mutate(subj_id = as.numeric(workerid)) %>%
select(subj_id, response, final_bonus) %>%
group_by(subj_id) %>%
summarise(
prolific_id = first(response[str_detect(response, "prolific_id")]),
final_bonus = first(final_bonus[!is.na(final_bonus)]),
.groups = "drop"
) %>%
# extract the prolific_id from the JSON string
mutate(
prolific_id = gsub(".*'prolific_id':\\s*'([^']+)'.*", "\\1", prolific_id),
final_bonus = as.numeric(final_bonus)
)
# anonymize and change worker id to subj_id
anonymize_clean <- function(df) {
df <- df %>%
select(-url,-proliferate.condition,-failed_audio, -failed_images, -failed_video,
-sequence_length,-internal_node_id,-view_history,-contains("browser"),-contains("platform"),
-contains("screen"),-contains("width"),-contains("height"),
-contains("failed"),-success,-event_history, -internal_node_id) %>%
filter(!str_detect(tolower(response), "prolific_id"))%>%
mutate(subj_id = as.numeric(workerid))
return(df)
}
df_all <- anonymize_clean(df_all)
df_all <- df_all %>%
# IMPORTANTLY: marks timeouts as incorrect
mutate(is_correct_numeric = ifelse(is_correct=="false" | timed_out == "1" |
timed_out == "true" | timed_out == 1, 0, 1)) %>%
group_by(subj_id) %>%
mutate(
gameA = ifelse(all(is.na(gameA_name)), NA,
first(gameA_name[!is.na(gameA_name) & !(gameA_name=="")])),
SR_isGameA = ifelse(all(is.na(gameA_isSR)), NA,
first(gameA_isSR[!is.na(gameA_isSR) & !(gameA_isSR == "")]))
) %>%
mutate(gameA_isSR = ifelse(SR_isGameA == "true", TRUE, FALSE), gameA_name = gameA) %>%
ungroup()
df_recent_subset <- df_all %>%
filter(trial_type == "sr_practice_response" | trial_type == "ds_practice_response" | trial_type == "rt_practice_trials" | trial_type == "sr_main_response" | trial_type == "ds_main_response" | trial_type == "rt_main_trials") %>%
select(-c(transition_type, gameB_name, game_A, game_B, backwards, score_an, score_pc, score_ls, is_correct, stimulus, target_shape, final_bonus)) %>%
ungroup() %>%
mutate(trial_index_num = as.numeric(trial_index)) %>%
mutate(trial_index = trial_index_num) %>%
select(-trial_index_num, -SR_isGameA, -gameA) %>%
arrange(subj_id, trial_index)
# create the pratice runs df and save it
practice_runs_subset_df <- df_recent_subset %>%
filter(trial_type == "sr_practice_response" | trial_type == "ds_practice_response" | trial_type == "rt_practice_trials") %>%
group_by(subj_id, trial_type) %>%
summarize(avg_accuracy = mean(is_correct_numeric))
# save the practice data to a cleaned csv
setwd("../data_cleaned/test_run/")
write.csv(practice_runs_subset_df, "practice_trials_cleaned.csv")
# exclude practice runs from the main dataset and create a df with the average performance per worker per task
all_runs_avg_subset <- df_recent_subset %>%
filter(trial_type == "sr_main_response" | trial_type == "ds_main_response" | trial_type == "rt_main_trials") %>%
group_by(subj_id, trial_type) %>%
summarize(avg_accuracy = mean(is_correct_numeric))
# make sure it's arranged in order and remove practice rows
df_recent_subset_analyze <- df_recent_subset %>%
filter(trial_type != "sr_practice_response" & trial_type != "ds_practice_response" & trial_type != "rt_practice_trials") %>%
arrange(subj_id, trial_index) %>%
ungroup() %>%
# add overall trial counts of each task
group_by(subj_id, game_type) %>%
arrange(trial_index) %>%
mutate(overall_type_count = row_number()) %>%
ungroup() %>%
# add the epoch numbers and block values
arrange(subj_id, trial_index) %>%
group_by(subj_id) %>%
mutate(
epoch_num = cumsum(game_type == "rest_task" & lag(game_type, default = first(game_type)) != "rest_task"),
block_num = ifelse(game_type == "rest_task" & follows_block_num != "null", follows_block_num, NA)
) %>%
fill(block_num, .direction = "up") %>%
mutate(
epoch_num = ifelse(is.na(epoch_num), 1, epoch_num)
) %>%
ungroup() %>%
# reset the epoch numbers to start from 1 for each participant
# get rid of epoch num for rest task
group_by(subj_id) %>%
mutate(
epoch_num = ifelse(epoch_num >= 0, dense_rank(epoch_num), epoch_num),
epoch_num = ifelse(game_type == "rest_task", NA, epoch_num)
) %>%
select(-option_to_end, -overall_num_rest_used, -end_rest_button_clicked, -responses, -timeout) %>%
ungroup() %>%
arrange(subj_id, trial_index)
df_recent_subset_analyze <- df_recent_subset_analyze %>%
mutate(na_trial = ifelse(is.na(timed_out), 1,0),
timed_out = ifelse(timed_out == "true" | timed_out == 1 | timed_out == "1", TRUE, FALSE)) %>%
mutate(rt = ifelse(timed_out == TRUE,NA,rt)) %>% # for all tasks, if timed out rt = 4200 or 5000 ms; for SR sometimes it's slightly above 4200 if it didn't catch it in time
mutate(rt_num = as.numeric(rt)) %>%
mutate(rt = rt_num) %>%
select(-rt_num)
# count rests taken per break (label rest chunk per participant (should be 30) and add a column which counts how many per break there are)
df_recent_subset_analyze <- df_recent_subset_analyze %>%
ungroup() %>%
arrange(subj_id, trial_index) %>%
group_by(subj_id) %>%
mutate(task_change = game_type != lag(game_type, default = "first_row"),
rest_chunk = cumsum(task_change & game_type == "rest_task"),
rest_chunk = ifelse(game_type == "rest_task", rest_chunk, NA)) %>%
ungroup() %>%
group_by(subj_id, rest_chunk) %>%
mutate(num_rest_in_chunk = sum(!is.na(rest_chunk))) %>%
select(-task_change) %>%
ungroup()
# save the cleaned subset data
setwd("../data_cleaned/test_run/")
write.csv(df_recent_subset_analyze, "main_trials_cleaned.csv")
# count how much each participant timed out (to make sure no participants exited the task early and that none of them just let the task play out without participating)
prop_timed_out <- df_recent_subset_analyze %>%
ungroup() %>%
group_by(subj_id, game_type) %>%
summarize(num_timed_out = sum(timed_out == TRUE), num_not_timed_out = sum(timed_out == FALSE), num_NA = sum(na_trial == 1)) %>%
mutate(total_trials = num_not_timed_out + num_timed_out,
prop_timed_out = num_timed_out / total_trials)
# save time out counts to the subj_id / bonus table
final_participant_data <- df_bonus_id %>%
left_join(prop_timed_out, by = "subj_id")
final_participant_data <- final_participant_data%>%
group_by(subj_id) %>%
mutate(max_timed_out_sr_ds = max(
case_when(
game_type %in% c("spatial_recall", "digit_span") ~ prop_timed_out,
TRUE ~ NA_real_
),na.rm = TRUE))
# bonus stuff used to be here, now its at the bottom of this cell
python_dict_to_json <- function(text) {
text %>%
str_replace_all("'", '"') %>%
str_replace_all("None", "null") %>%
str_replace_all("True", "true") %>%
str_replace_all("False", "false")
}
df_separated <- df_separated %>%
mutate(response = map_chr(response, python_dict_to_json))
# Parse rest survey responses
rest_responses <- df_separated %>%
filter(survey_type == "rest_survey") %>%
mutate(
parsed = map(response, possibly(fromJSON, otherwise = NULL))
) %>%
unnest_wider(parsed) %>%
select(-response, -survey_type)
# Parse game survey responses
game_responses <- df_separated %>%
filter(survey_type == "game_survey") %>%
mutate(
parsed = map(response, possibly(fromJSON, otherwise = NULL))
) %>%
unnest_wider(parsed) %>%
select(-response, -survey_type)
# Join them back together
survey_cleaned <- rest_responses %>%
full_join(game_responses, by = "subj_id", suffix = c("_rest", "_game"))
setwd("../data_cleaned/test_run/")
write.csv(survey_cleaned, "survey_cleaned.csv", row.names = FALSE)
# check to see if any participants timed out too much on spatial recall or digit span
# too many timeouts = >85% (if they did, look into their responses to see if they tried to respond)
# also check to see if anyone has <150 trials for ds or sr (means they didn't complete the task for some reason)
df_bonus_id <- final_participant_data %>%
ungroup() %>%
mutate(flagged_time_outs = ifelse(max_timed_out_sr_ds > 0.85, TRUE, FALSE),
flagged_few_trials = ifelse(game_type != "rest_task" & total_trials < 150, TRUE, FALSE),
flagged_has_nas = ifelse(num_NA != 0, TRUE, FALSE)) # figure out whats happening w 539 subj
# print the ones who you should look into more
df_bonus_id %>%
filter(flagged_time_outs == TRUE | flagged_few_trials == TRUE | flagged_has_nas == TRUE) %>%
# filter(!(prolific_id %in% already_paid_1$prolific_id)) %>% #this lets me filter out those I already approved (did everyone in batch 1)
# filter(!(prolific_id %in% already_paid_2$prolific_id)) %>% #this lets me filter out those I already approved/looked at
print() %>%
select(subj_id, prolific_id, flagged_time_outs, max_timed_out_sr_ds, flagged_few_trials, flagged_has_nas) %>%
distinct()
# filter out/exclude those who have more than 85% na trials (for sr or ds)
exclude_has_nas <- df_bonus_id%>%
filter(flagged_has_nas == TRUE) %>%
select(subj_id)
exclude_has_nas
# save the timed out data which you can save in the anonymous folder
prop_timed_out <- df_bonus_id %>%
# filter(!(subj_id %in% exclude_has_nas)) %>% # exclude for now
select(-prolific_id, -final_bonus, -max_timed_out_sr_ds)
setwd("../data_cleaned/test_run/")
write.csv(prop_timed_out, "timed_out_data_cleaned.csv")
# clean the bonus_id df which you will then use for paying bonuses (DO NOT UPLOAD THIS FILE TO data_anonymized FOLDER) but can update to data/ because it's hidden with gitignore (can then upload this to prolific for an easy way to pay bonuses)
setwd("../data/test_run/")
# for batch 1
subj_to_exclude =  exclude_has_nas$subj_id #excluding the ones with incomplete data
df_bonus_id_b1 <- df_bonus_id %>%
select(subj_id, prolific_id, final_bonus) %>%
distinct() %>%
# filter(!(subj_id %in% subj_to_exclude)) %>%
# filter(!(prolific_id %in% already_paid_1$prolific_id)) %>% #this lets me filter out those I already approved/looked at
select(prolific_id, final_bonus)
write.table(df_bonus_id_b1, "bonus_payments.txt", sep=",", row.names=FALSE, col.names=FALSE, quote=FALSE)
# find certain prolific ids here
# df_bonus_id %>%
#   filter(prolific_id %in% c(""))
df_bonus_id <- df_bonus_id %>%
select(-prolific_id)
df_bonus_id_b1 <- df_bonus_id_b1 %>%
select(-prolific_id)
df_bonus_id_b2 <- df_bonus_id_b2 %>%
select(-prolific_id)
# clean the bonus_id df which you will then use for paying bonuses (DO NOT UPLOAD THIS FILE TO data_anonymized FOLDER) but can update to data/ because it's hidden with gitignore (can then upload this to prolific for an easy way to pay bonuses)
setwd("../data/test_run/")
# for batch 1
subj_to_exclude =  exclude_has_nas$subj_id #excluding the ones with incomplete data
df_bonus_id_b1 <- df_bonus_id %>%
select(subj_id, prolific_id, final_bonus) %>%
distinct() %>%
# filter(!(subj_id %in% subj_to_exclude)) %>%
# filter(!(prolific_id %in% already_paid_1$prolific_id)) %>% #this lets me filter out those I already approved/looked at
select(prolific_id, final_bonus)
knitr::opts_chunk$set(echo = TRUE)
library("knitr") # for knitting things
library("tidyverse") # for all things tidyverse
library("broom")      # for tidying up linear models
library("car")        # for running ANOVAs
library("afex")       # also for running ANOVAs
library("emmeans")    # for calculating constrasts
library(jsonlite)
# set the default ggplot theme
theme_set(theme_classic())
# exp vars
sr_practice_num <- 4
sr_per_block <- 10
ds_practice_num <- 4
ds_per_block <- 10
rt_practice_num <- 4
rt_per__block_max <- 20
num_groups <- 10
num_blocks_per_group <- 3
num_blocks_overall <- num_groups * num_blocks_per_group
# data from proliferate
setwd("../data/test_run/")
data_file <- list.files(pattern = "\\-merged.csv$")
# Function to read a CSV file and convert all columns to character type
read_csv_as_character <- function(file) {
df <- read.csv(file, stringsAsFactors = FALSE)
df[] <- lapply(df, as.character)  # Apply as.character to each column
return(df)
}
df_all <- read_csv_as_character(data_file)
# LEAVE COMMENTED OUT UNTIL YOU GET MORE PARTICIPANTS THEN RUN THIS ONCE AND COMMENT OUT AGAIN
# read in previous subj_ids that you've already approved/paid so you don't double do it
# setwd("../data/test_run/")
# already_paid <- read.csv("already_paid.txt",header = FALSE,
#                         col.names = "prolific_id",
#                         stringsAsFactors = FALSE)
# get the participant id and bonus for repayment
df_bonus_id <- df_all %>%
filter(str_detect(tolower(response), "prolific_id") | !is.na(final_bonus)) %>%
mutate(subj_id = as.numeric(workerid)) %>%
select(subj_id, response, final_bonus) %>%
group_by(subj_id) %>%
summarise(
prolific_id = first(response[str_detect(response, "prolific_id")]),
final_bonus = first(final_bonus[!is.na(final_bonus)]),
.groups = "drop"
) %>%
# extract the prolific_id from the JSON string
mutate(
prolific_id = gsub(".*'prolific_id':\\s*'([^']+)'.*", "\\1", prolific_id),
final_bonus = as.numeric(final_bonus)
)
# anonymize and change worker id to subj_id
anonymize_clean <- function(df) {
df <- df %>%
select(-url,-proliferate.condition,-failed_audio, -failed_images, -failed_video,
-sequence_length,-internal_node_id,-view_history,-contains("browser"),-contains("platform"),
-contains("screen"),-contains("width"),-contains("height"),
-contains("failed"),-success,-event_history, -internal_node_id) %>%
filter(!str_detect(tolower(response), "prolific_id"))%>%
mutate(subj_id = as.numeric(workerid))
return(df)
}
df_all <- anonymize_clean(df_all)
df_all <- df_all %>%
# IMPORTANTLY: marks timeouts as incorrect
mutate(is_correct_numeric = ifelse(is_correct=="false" | timed_out == "1" |
timed_out == "true" | timed_out == 1, 0, 1)) %>%
group_by(subj_id) %>%
mutate(
gameA = ifelse(all(is.na(gameA_name)), NA,
first(gameA_name[!is.na(gameA_name) & !(gameA_name=="")])),
SR_isGameA = ifelse(all(is.na(gameA_isSR)), NA,
first(gameA_isSR[!is.na(gameA_isSR) & !(gameA_isSR == "")]))
) %>%
mutate(gameA_isSR = ifelse(SR_isGameA == "true", TRUE, FALSE), gameA_name = gameA) %>%
ungroup()
df_recent_subset <- df_all %>%
filter(trial_type == "sr_practice_response" | trial_type == "ds_practice_response" | trial_type == "rt_practice_trials" | trial_type == "sr_main_response" | trial_type == "ds_main_response" | trial_type == "rt_main_trials") %>%
select(-c(transition_type, gameB_name, game_A, game_B, backwards, score_an, score_pc, score_ls, is_correct, stimulus, target_shape, final_bonus)) %>%
ungroup() %>%
mutate(trial_index_num = as.numeric(trial_index)) %>%
mutate(trial_index = trial_index_num) %>%
select(-trial_index_num, -SR_isGameA, -gameA) %>%
arrange(subj_id, trial_index)
# create the pratice runs df and save it
practice_runs_subset_df <- df_recent_subset %>%
filter(trial_type == "sr_practice_response" | trial_type == "ds_practice_response" | trial_type == "rt_practice_trials") %>%
group_by(subj_id, trial_type) %>%
summarize(avg_accuracy = mean(is_correct_numeric))
# save the practice data to a cleaned csv
setwd("../data_cleaned/test_run/")
write.csv(practice_runs_subset_df, "practice_trials_cleaned.csv")
# exclude practice runs from the main dataset and create a df with the average performance per worker per task
all_runs_avg_subset <- df_recent_subset %>%
filter(trial_type == "sr_main_response" | trial_type == "ds_main_response" | trial_type == "rt_main_trials") %>%
group_by(subj_id, trial_type) %>%
summarize(avg_accuracy = mean(is_correct_numeric))
# make sure it's arranged in order and remove practice rows
df_recent_subset_analyze <- df_recent_subset %>%
filter(trial_type != "sr_practice_response" & trial_type != "ds_practice_response" & trial_type != "rt_practice_trials") %>%
arrange(subj_id, trial_index) %>%
ungroup() %>%
# add overall trial counts of each task
group_by(subj_id, game_type) %>%
arrange(trial_index) %>%
mutate(overall_type_count = row_number()) %>%
ungroup() %>%
# add the epoch numbers and block values
arrange(subj_id, trial_index) %>%
group_by(subj_id) %>%
mutate(
epoch_num = cumsum(game_type == "rest_task" & lag(game_type, default = first(game_type)) != "rest_task"),
block_num = ifelse(game_type == "rest_task" & follows_block_num != "null", follows_block_num, NA)
) %>%
fill(block_num, .direction = "up") %>%
mutate(
epoch_num = ifelse(is.na(epoch_num), 1, epoch_num)
) %>%
ungroup() %>%
# reset the epoch numbers to start from 1 for each participant
# get rid of epoch num for rest task
group_by(subj_id) %>%
mutate(
epoch_num = ifelse(epoch_num >= 0, dense_rank(epoch_num), epoch_num),
epoch_num = ifelse(game_type == "rest_task", NA, epoch_num)
) %>%
select(-option_to_end, -overall_num_rest_used, -end_rest_button_clicked, -responses, -timeout) %>%
ungroup() %>%
arrange(subj_id, trial_index)
df_recent_subset_analyze <- df_recent_subset_analyze %>%
mutate(na_trial = ifelse(is.na(timed_out), 1,0),
timed_out = ifelse(timed_out == "true" | timed_out == 1 | timed_out == "1", TRUE, FALSE)) %>%
mutate(rt = ifelse(timed_out == TRUE,NA,rt)) %>% # for all tasks, if timed out rt = 4200 or 5000 ms; for SR sometimes it's slightly above 4200 if it didn't catch it in time
mutate(rt_num = as.numeric(rt)) %>%
mutate(rt = rt_num) %>%
select(-rt_num)
# count rests taken per break (label rest chunk per participant (should be 30) and add a column which counts how many per break there are)
df_recent_subset_analyze <- df_recent_subset_analyze %>%
ungroup() %>%
arrange(subj_id, trial_index) %>%
group_by(subj_id) %>%
mutate(task_change = game_type != lag(game_type, default = "first_row"),
rest_chunk = cumsum(task_change & game_type == "rest_task"),
rest_chunk = ifelse(game_type == "rest_task", rest_chunk, NA)) %>%
ungroup() %>%
group_by(subj_id, rest_chunk) %>%
mutate(num_rest_in_chunk = sum(!is.na(rest_chunk))) %>%
select(-task_change) %>%
ungroup()
# save the cleaned subset data
setwd("../data_cleaned/test_run/")
write.csv(df_recent_subset_analyze, "main_trials_cleaned.csv")
# count how much each participant timed out (to make sure no participants exited the task early and that none of them just let the task play out without participating)
prop_timed_out <- df_recent_subset_analyze %>%
ungroup() %>%
group_by(subj_id, game_type) %>%
summarize(num_timed_out = sum(timed_out == TRUE), num_not_timed_out = sum(timed_out == FALSE), num_NA = sum(na_trial == 1)) %>%
mutate(total_trials = num_not_timed_out + num_timed_out,
prop_timed_out = num_timed_out / total_trials)
# save time out counts to the subj_id / bonus table
final_participant_data <- df_bonus_id %>%
left_join(prop_timed_out, by = "subj_id")
final_participant_data <- final_participant_data%>%
group_by(subj_id) %>%
mutate(max_timed_out_sr_ds = max(
case_when(
game_type %in% c("spatial_recall", "digit_span") ~ prop_timed_out,
TRUE ~ NA_real_
),na.rm = TRUE))
# bonus stuff used to be here, now its at the bottom of this cell
python_dict_to_json <- function(text) {
text %>%
str_replace_all("'", '"') %>%
str_replace_all("None", "null") %>%
str_replace_all("True", "true") %>%
str_replace_all("False", "false")
}
df_separated <- df_separated %>%
mutate(response = map_chr(response, python_dict_to_json))
# Parse rest survey responses
rest_responses <- df_separated %>%
filter(survey_type == "rest_survey") %>%
mutate(
parsed = map(response, possibly(fromJSON, otherwise = NULL))
) %>%
unnest_wider(parsed) %>%
select(-response, -survey_type)
# Parse game survey responses
game_responses <- df_separated %>%
filter(survey_type == "game_survey") %>%
mutate(
parsed = map(response, possibly(fromJSON, otherwise = NULL))
) %>%
unnest_wider(parsed) %>%
select(-response, -survey_type)
# Join them back together
survey_cleaned <- rest_responses %>%
full_join(game_responses, by = "subj_id", suffix = c("_rest", "_game"))
setwd("../data_cleaned/test_run/")
write.csv(survey_cleaned, "survey_cleaned.csv", row.names = FALSE)
# check to see if any participants timed out too much on spatial recall or digit span
# too many timeouts = >85% (if they did, look into their responses to see if they tried to respond)
# also check to see if anyone has <150 trials for ds or sr (means they didn't complete the task for some reason)
df_bonus_id <- final_participant_data %>%
ungroup() %>%
mutate(flagged_time_outs = ifelse(max_timed_out_sr_ds > 0.85, TRUE, FALSE),
flagged_few_trials = ifelse(game_type != "rest_task" & total_trials < 150, TRUE, FALSE),
flagged_has_nas = ifelse(num_NA != 0, TRUE, FALSE)) # figure out whats happening w 539 subj
# print the ones who you should look into more
df_bonus_id %>%
filter(flagged_time_outs == TRUE | flagged_few_trials == TRUE | flagged_has_nas == TRUE) %>%
# filter(!(prolific_id %in% already_paid_1$prolific_id)) %>% #this lets me filter out those I already approved (did everyone in batch 1)
# filter(!(prolific_id %in% already_paid_2$prolific_id)) %>% #this lets me filter out those I already approved/looked at
print() %>%
select(subj_id, prolific_id, flagged_time_outs, max_timed_out_sr_ds, flagged_few_trials, flagged_has_nas) %>%
distinct()
# filter out/exclude those who have more than 85% na trials (for sr or ds)
exclude_has_nas <- df_bonus_id%>%
filter(flagged_has_nas == TRUE) %>%
select(subj_id)
exclude_has_nas
# save the timed out data which you can save in the anonymous folder
prop_timed_out <- df_bonus_id %>%
# filter(!(subj_id %in% exclude_has_nas)) %>% # exclude for now
select(-prolific_id, -final_bonus, -max_timed_out_sr_ds)
setwd("../data_cleaned/test_run/")
write.csv(prop_timed_out, "timed_out_data_cleaned.csv")
# clean the bonus_id df which you will then use for paying bonuses (DO NOT UPLOAD THIS FILE TO data_anonymized FOLDER) but can update to data/ because it's hidden with gitignore (can then upload this to prolific for an easy way to pay bonuses)
setwd("../data/test_run/")
# for batch 1
subj_to_exclude =  exclude_has_nas$subj_id #excluding the ones with incomplete data
df_bonus_id_b1 <- df_bonus_id %>%
select(subj_id, prolific_id, final_bonus) %>%
distinct() %>%
# filter(!(subj_id %in% subj_to_exclude)) %>%
# filter(!(prolific_id %in% already_paid_1$prolific_id)) %>% #this lets me filter out those I already approved/looked at
select(prolific_id, final_bonus)
write.table(df_bonus_id_b1, "bonus_payments.txt", sep=",", row.names=FALSE, col.names=FALSE, quote=FALSE)
# find certain prolific ids here
# df_bonus_id %>%
#   filter(prolific_id %in% c(""))
df_bonus_id <- df_bonus_id %>%
select(-prolific_id)
df_bonus_id_b1 <- df_bonus_id_b1 %>%
select(-prolific_id)
all_runs_avg_subset %>%
ggplot(aes(x=trial_type,y=avg_accuracy,color=subj_id)) +
geom_point(alpha = 0.5,position = position_jitter(width = 0.2,
height = 0)) +
# facet_wrap(~trial_type)+
stat_summary(fun.data = "mean_cl_boot",
geom = "pointrange",
color = "black",
fill = "yellow",
shape = 21,
size = 1)+
stat_summary(fun.y = mean, geom = "text", aes(label = round(..y.., 2)), hjust = -.5) +
labs(x="Game types",y="Average accuracy per participant on given game type")+
ggtitle("Average participant performance on each game: pre-exclusion")
rt_overall_avgs <- df_recent_subset_analyze %>%
ungroup() %>%
filter(timed_out == FALSE) %>%
group_by(subj_id, game_type) %>%
summarize(rt_avg = mean(rt))
rt_overall_avgs %>%
ggplot(aes(x=game_type,y=rt_avg,color=subj_id)) +
geom_point(alpha = 0.5,position = position_jitter(width = 0.2,
height = 0)) +
# facet_wrap(~trial_type)+
stat_summary(fun.data = "mean_cl_boot",
geom = "pointrange",
color = "black",
fill = "yellow",
shape = 21,
size = 1)+
stat_summary(fun.y = mean, geom = "text", aes(label = round(..y.., 2)), hjust = -.5) +
labs(x="Game types",y="Average rt per participant on given game type")+
ggtitle("Average participant rt on each game: pre-exclusion")
df_recent_subset_analyze <- df_recent_subset_analyze %>%
select(-correct_response, -rest_trial_num, -end_rest)
avg_accuracy_blocks <- df_recent_subset_analyze %>%
ungroup() %>%
group_by(subj_id, block_num, group_num, game_type) %>%
summarise(avg_accuracy = mean(is_correct_numeric))
install.packages("devtools")
devtools::install_github("IRkernel/IRkernel")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
devtools::install_github("IRkernel/IRkernel")
IRkernel::installspec()
IRkernel::installspec()
